# XRDrone

**Sponsor:** Prof. Raffaele De Amicis  
**Course:** CS 461‚Äì463 (Capstone 2025‚Äì2026)  
**Institution:** Oregon State University  
**Organization:** XRDrone Team

---

## üõ∞Ô∏è Project Overview
XRDrone is a real-time drone-to-VR streaming and object recognition system. The project aims to build a **Unity-based application** (target: Android/Meta Quest 2) that receives **live video from a DJI Neo drone**, renders it in **immersive 3D space**, and performs **on-device object detection** to overlay visual cues such as bounding boxes, labels, or shader-based highlights.

### **Core Objectives**
- **Drone Video to Quest 2:**  
  Stream ‚â• 720p video at ‚â• 24 FPS with ‚â§ 300 ms glass-to-glass latency, rendered on a hemispherical surface to reduce distortion.
- **On-Device Vision:**  
  Detect at least two object classes (e.g., ‚Äútree,‚Äù ‚Äúperson,‚Äù ‚Äúvehicle‚Äù) in real time (‚â• 15 FPS) using optimized ML models.
- **VR User Experience:**  
  Provide a cockpit-style HUD showing stream status, detection confidence, and toggles for overlays or recentering.
- **Engineering Deliverables:**  
  Document architecture, streaming protocol rationale, model choice, benchmarking results, and safety/ethical notes.

---

## üìä Acceptance Criteria
| Category | Target Metric |
|-----------|----------------|
| Streaming Reliability | ‚â• 24 FPS, < 2 % dropped frames, recover from forced disconnect |
| Latency | ‚â§ 300 ms median glass-to-glass |
| Vision Accuracy & Speed | ‚â• 0.5 F1 on labeled dataset (‚â• 150 frames), ‚â• 15 FPS inference |
| VR UX & Effects | Readable overlays, unobtrusive HUD, ‚â• 1 shader/VFX linked to detections |
| Engineering Quality | Clear architecture, reproducible build, configuration, and logging |

---

## üë• Team Members

| Name | Bio |
|------|------|
| **William Brennan** | Interested in VR and has prior experience coding in Unreal Engine. |
| **Troy Diaz** | Worked on a machine learning project with large image datasets and aims to apply that experience to XRDrone‚Äôs real-time detection. |
| **Balakrishna Thirumavalavan** | Drawn to the project‚Äôs focus on VR display overlays and intrigued by its real-time detection functionality. |
| **Guillermo Morales** | Interested in AR/VR and machine learning for human‚Äìcomputer interaction. |

---

## üí¨ Communication & Cadence
- **Primary Channel:** Microsoft Teams (OSU Capstone workspace)  
- **Team Meetings:** Fridays 10‚Äì11 AM in Person
- **TA Meetings:** Fridays 11 AM on Zoom  
- **Sponsor Meetings:** Time TBD with Prof. Raffaele De Amicis
- **Response-Time Expectation:** Pull requests and messages are reviewed within 24 hours
- **Stand-ups:** Mondays and Thursdays ‚Äì 10-minute check-ins on Teams  

---

## üîÄ Branching & Reviews
- **Default branch:** `main`
- **Branch flow:** `feature/* ‚Üí pull request ‚Üí ‚â•1 review ‚Üí merge`
- **Review cadence:** All PRs reviewed within 24 hours via Teams notification.
- **PR template:** `.github/PULL_REQUEST_TEMPLATE.md` created to guide contributions.

---

## üß∞ Tech Stack
- TBD

---

## üß© Repository Layout
XRDrone/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îú‚îÄ‚îÄ PULL_REQUEST_TEMPLATE.md      
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci.yml                    
‚îú‚îÄ‚îÄ LICENSE                          
‚îú‚îÄ‚îÄ README.md                        
‚îî‚îÄ‚îÄ XRDrone Description.pdf    

---
## ‚öñÔ∏è License
This project is licensed under the MIT License ‚Äì see the [LICENSE](./LICENSE) file for details.
---
## üôè Acknowledgements
Special thanks to **Prof. Raffaele De Amicis** for project sponsorship and guidance,  
and to Oregon State University‚Äôs School of EECS for supporting the XRDrone Capstone.
---

